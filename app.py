# Archivo: app.py (Versi√≥n 5.0 - MVP Final Modular)

import streamlit as st
from openai import OpenAI
import io 

# --- Importamos NUESTRO propio motor de RAG ---
from rag_utils import build_rag_chain

# --- 0. INICIALIZACI√ìN DEL CLIENTE OPENAI ---
try:
    API_KEY = st.secrets["OPENAI_API_KEY"]
    client = OpenAI(api_key=API_KEY)
except Exception as e:
    st.error(f"Error al inicializar cliente OpenAI: {e}")
    st.stop()

# --- 1. CONFIGURACI√ìN DE LA P√ÅGINA ---
st.set_page_config(
    page_title="EstudIA MVP",
    page_icon="ü§ñ",
    layout="centered",
    initial_sidebar_state="collapsed",
)



# --- 2. T√çTULO Y DESCRIPCI√ìN ---
st.title("ü§ñ Bienvenido al MVP de EstudIA")
st.markdown("S√∫banse al barco. ¬°Vamos a transformar la educaci√≥n!")

# --- 3. SEPARACI√ìN DE P√ÅGINAS ---
tab1, tab2 = st.tabs([
    "üéôÔ∏è Funci√≥n 1: Transcriptor y Resumidor", 
    "üßë‚Äçüè´ Funciones 2 y 3: Chat Interactivo"
])

# --- PESTA√ëA 1: RESUMIDOR DE CLASES (Ahora con RAG) ---
with tab1:
    st.header("üéôÔ∏è Funci√≥n 1: Transcriptor y Resumidor")
    st.write("Sube el audio de una clase y obt√©n tu resumen. Luego puedes activa un chat para preguntar sobre √©l.")
    
    uploaded_audio = st.file_uploader(
        "Sube tu archivo de audio (mp3, m4a, wav):", 
        type=["mp3", "m4a", "wav"],
        key="audio_uploader" 
    )
    
    if uploaded_audio:
        st.audio(uploaded_audio)
        
        if st.button("Transcribir y Resumir Audio"):
            with st.spinner("Procesando audio... (Esto puede tardar un momento) ‚è≥"):
                try:
                    # 1. TRANSCRIPCI√ìN CON WHISPER
                    st.subheader("1. Transcripci√≥n de la Clase (Whisper)")
                    audio_bytes = io.BytesIO(uploaded_audio.read())
                    audio_bytes.name = uploaded_audio.name
                    transcript_response = client.audio.transcriptions.create(
                        model="whisper-1",
                        file=audio_bytes,
                        response_format="text"
                    )
                    transcript_text = transcript_response
                    st.success("¬°Audio transcrito!")
                    st.text_area("Texto de la clase:", transcript_text, height=150)

                    # --- INICIO DEL "HACK" DE RAG ---
                    st.session_state["pitch_transcrito"] = transcript_text
                    st.success("¬°Transcripci√≥n guardada! Ve a la Pesta√±a 2 y selecciona 'Modo: Chat con tu Pitch' para preguntar sobre este texto.")
                    # --- FIN DEL "HACK" DE RAG ---

                    # 2. RESUMEN CON GPT-4
                    st.subheader("2. Resumen y Puntos Clave (GPT-4)")
                    system_prompt = """
                                    Eres "EstudIA", un asistente acad√©mico experto, amigable y perspicaz.
                                    Tu misi√≥n es leer la transcripci√≥n de una clase (de cualquier materia, desde C√°lculo hasta Filosof√≠a) y ayudar al estudiante a entender lo esencial.

                                    Por favor, responde SIEMPRE usando la siguiente estructura Markdown. S√© conciso y ve al grano:

                                    **Resumen:**
                                    (Aqu√≠ va tu resumen conciso, idealmente en 3 frases.)

                                    **Puntos Clave (los 5 conceptos m√°s importantes):**
                                     1.  [Punto clave 1]
                                     2.  [Punto clave 2]
                                     3.  [Punto clave 3]
                                     4.  [Punto clave 4]
                                     5.  [Punto clave 5]

                                        (No a√±adas saludos ni despedidas, solo la estructura.)
                                            """
                    summary_response = client.chat.completions.create(
                        model="gpt-4-turbo",
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": transcript_text}
                        ]
                    )
                    summary_text = summary_response.choices[0].message.content
                    st.success("¬°Resumen generado!")
                    st.markdown(summary_text)

                except Exception as e:
                    st.error(f"Ocurri√≥ un error: {e}")

# --- PESTA√ëA 2: TUTOR ESTUDIA ---
with tab2:
    st.header("üßë‚Äçüè´ Funciones 2 y 3: Chat Interactivo")
    st.write("Demuestra c√≥mo el tutor gu√≠a, se adapta, o chatea sobre un texto espec√≠fico.")

    # --- SELECTOR DE MODO (¬°AHORA CON 3 MODOS!) ---
    demo_mode = st.selectbox(
        "Selecciona el Modo de Demo:",
        (
            "Modo: Alumno Nuevo (Tutor gu√≠a)", 
            "Modo: Chat con tu Pitch (RAG)" # <- ¬°LA NUEVA OPCI√ìN!
        )
    )
    
    # --- L√ìGICA DE PROMPTS PARA MODO 1 y 2 ---
    PROMPT_ALUMNO_NUEVO = """
    Eres "EstudIA", un tutor socr√°tico experto, tienes prohibido dar las respuestas, solo guiar en el resultado de aprendizaje paso por paso a me dida que transcurre al conversaci√≥n...
    IMPORTANTE: Cuando escribas f√≥rmulas matem√°ticas, usa SIEMPRE la sintaxis LaTeX...
    """ # (Abreviado, es tu V4.4)
    
    PROMPT_PERFIL_MARIA = """
    Eres "EstudIA", un tutor socr√°tico experto...
    ---
    **INFORMACI√ìN CONFIDENCIAL DEL ESTUDIANTE (MODO DEMO):**
    * **Nombre:** Mar√≠a.
    * **Punto D√©bil Detectado:** ...Derivadas...
    ---
    IMPORTANTE: Cuando escribas f√≥rmulas matem√°ticas, usa SIEMPRE la sintaxis LaTeX...
    """ # (Abreviado, es tu V4.4)

    # --- L√ìGICA DEL "ROUTER" ---
    
    # MODO 1 y 2: El Chat Manual (Tu V4.4 "Golden" que ya funciona)
    if demo_mode in ("Modo: Alumno Nuevo (Tutor gu√≠a)", "Modo: Perfil 'Mar√≠a' (DEMO)"):
        
        if demo_mode == "Modo: Perfil 'Mar√≠a' (DEMO)":
            system_prompt_a_usar = PROMPT_PERFIL_MARIA
            st.warning("Perfil 'Mar√≠a' cargado (d√©bil en derivadas). El bot ahora se adaptar√° a ella.")
            session_key = "chat_history_maria" 
        else:
            system_prompt_a_usar = PROMPT_ALUMNO_NUEVO
            st.success("Perfil 'Alumno Nuevo' cargado. El bot actuar√° como un tutor socr√°tico general.")
            session_key = "chat_history_nuevo"
        
        if session_key not in st.session_state:
            st.session_state[session_key] = []
        chat_history = st.session_state[session_key]

        try:
            # (Aqu√≠ va TODO tu c√≥digo de chat manual de la V4.4)
            # --- MOSTRAR HISTORIAL (Modo 1 y 2) ---
            for msg in chat_history:
                msg_type = "user" if msg["role"] == "user" else "assistant"
                with st.chat_message(msg_type):
                    st.markdown(msg["content"]) # Usamos markdown

            # --- INPUT DEL USUARIO (Modo 1 y 2) ---
            if user_input := st.chat_input("Escribe tu duda socr√°tica aqu√≠..."):
                st.chat_message("user").write(user_input)
                chat_history.append({"role": "user", "content": user_input})
                
                with st.chat_message("assistant"):
                    with st.spinner("EstudIA (Socr√°tico) est√° pensando..."):
                        messages = [{"role": "system", "content": system_prompt_a_usar}]
                        messages.extend(chat_history) # M√°s limpio
                        
                        response = client.chat.completions.create(
                            model="gpt-4-turbo",
                            messages=messages
                        )
                        response_text = response.choices[0].message.content
                        
                        # Tu hack de LaTeX
                        response_text = response_text.replace('\\[', '$$').replace('\\]', '$$')
                        response_text = response_text.replace('\\(', '$').replace('\\)', '$')
                        
                        st.markdown(response_text) 
                        chat_history.append({"role": "assistant", "content": response_text})
                        st.session_state[session_key] = chat_history
        
        except Exception as e:
            st.error(f"Error al inicializar el chat socr√°tico: {e}")

    # MODO 3: El Chat RAG (¬°La Nueva Funci√≥n 5!)
    elif demo_mode == "Modo: Chat con tu Pitch (RAG)":
        
        st.info("Modo RAG: El bot ahora solo responder√° bas√°ndose en el texto de la Pesta√±a 1.")
        
        # 1. Chequeamos si la transcripci√≥n existe
        if "pitch_transcrito" not in st.session_state:
            st.error("¬°Error! Primero debes 'Transcribir y Resumir' un audio en la Pesta√±a 1.")
            st.stop()

        # 2. Construimos (o cargamos desde cach√©) la cadena RAG
        transcript_text = st.session_state["pitch_transcrito"]
        try:
            # ¬°Llamamos a nuestro motor RAG!
            rag_chain = build_rag_chain(transcript_text, API_KEY)
            
            if rag_chain is None:
                st.error("Error al construir el motor RAG. Revisa los logs.")
                st.stop()
            
            # 3. Inicializamos la memoria de chat RAG
            session_key_rag = "chat_history_rag"
            if session_key_rag not in st.session_state:
                st.session_state[session_key_rag] = []
            
            chat_history_rag = st.session_state[session_key_rag]

            # 4. Mostrar historial RAG
            for msg in chat_history_rag:
                msg_type = "user" if msg["role"] == "user" else "assistant"
                with st.chat_message(msg_type):
                    st.markdown(msg["content"])

            # 5. Input del usuario RAG
            if user_input := st.chat_input("Pregunta sobre el pitch aqu√≠..."):
                st.chat_message("user").write(user_input)
                
                with st.chat_message("assistant"):
                    with st.spinner("EstudIA (RAG) est√° buscando en el pitch..."):
                        
                        # ¬°Aqu√≠ llamamos a la cadena RAG!
                        # Para el MVP, la memoria no es crucial, as√≠ que la enviamos simple
                        response = rag_chain.invoke({
                            "input": user_input
                        })
                        
                        response_text = response
                        st.markdown(response_text)
                        
                        # Actualizamos la memoria RAG (simple)
                        st.session_state[session_key_rag].append({"role": "user", "content": user_input})
                        st.session_state[session_key_rag].append({"role": "assistant", "content": response_text})

        except Exception as e:
            st.error(f"Error al construir la cadena RAG: {e}")
            st.error("El fantasma de LangChain atac√≥ de nuevo. Revisa la terminal.")